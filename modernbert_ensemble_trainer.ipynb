{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036f26dc",
   "metadata": {},
   "source": [
    "# ModernBERT Ensemble Model Training\n",
    "\n",
    "This notebook implements an ensemble approach for hate speech detection, where each individual model is trained on a specific identity term dataset. The ensemble combines predictions using different voting mechanisms, including majority voting and weighted averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305b8b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_recall_fscore_support, confusion_matrix, balanced_accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from transformers import pipeline\n",
    "from checklist.pred_wrapper import PredictorWrapper\n",
    "from checklist.test_types import MFT\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import dataHandler as dh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccba1e7",
   "metadata": {},
   "source": [
    "## 1. Setup Environment and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30fd41fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Base model ID for ModernBERT\n",
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "\n",
    "# Load the ModernBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# Path to store ensemble models\n",
    "ensemble_models_dir = \"modernbert_ensemble\"\n",
    "os.makedirs(ensemble_models_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a82877",
   "metadata": {},
   "source": [
    "## 2. Prepare Individual Datasets by Identity Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b576e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity terms to be used for individual models: ['asian', 'black', 'chinese', 'jewish', 'latino', 'lgbtq', 'mental_dis', 'mexican', 'middle_east', 'muslim', 'native_american', 'physical_dis', 'women']\n"
     ]
    }
   ],
   "source": [
    "# Get the list of identity terms\n",
    "id_terms = dh.getListOfIdTerms()[:-1]\n",
    "print(f\"Identity terms to be used for individual models: {id_terms}\")\n",
    "\n",
    "# Function to tokenize dataset\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True, return_tensors=\"pt\", max_length=140)\n",
    "\n",
    "# Function to prepare dataset for a specific identity term\n",
    "def prepare_id_term_dataset(id_term, test_size=0.2):\n",
    "    print(f\"Preparing dataset for identity term: {id_term}\")\n",
    "    \n",
    "    # Get dataset for this identity term\n",
    "    dataset = dh.toxigenDataset(id_term, test_size=test_size)\n",
    "    \n",
    "    # Rename label column to labels for compatibility with Trainer\n",
    "    if \"label\" in dataset[\"train\"].features.keys():\n",
    "        dataset = dataset.rename_column(\"label\", \"labels\")\n",
    "    \n",
    "    # Tokenize the dataset\n",
    "    tokenized_dataset = dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "    \n",
    "    print(f\"  Train set size: {len(tokenized_dataset['train'])} samples\")\n",
    "    print(f\"  Test set size: {len(tokenized_dataset['test'])} samples\")\n",
    "    \n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "009684a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset for identity term: asian\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2759ea9990814ed792381d74c4e8523a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15907 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92205ce1f0a4464791dd16e23b0c3411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3977 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train set size: 15907 samples\n",
      "  Test set size: 3977 samples\n",
      "Preparing dataset for identity term: black\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b146718eab4f4214aaf39e73fa6cced1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15902 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0151ee1c12c40b38e62559061357583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3976 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train set size: 15902 samples\n",
      "  Test set size: 3976 samples\n",
      "Preparing dataset for identity term: chinese\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac4c25dcd3b471da3cab8c3a51ae64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15247 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3147933add44774a2103919140eae95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3812 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train set size: 15247 samples\n",
      "  Test set size: 3812 samples\n",
      "Preparing dataset for identity term: jewish\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb85cafbacff425ea03d4e658e647284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15634 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3626be7a1ab54d0b992e34905654c256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3908 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train set size: 15634 samples\n",
      "  Test set size: 3908 samples\n",
      "Preparing dataset for identity term: latino\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "416cd9bfddf2469ea3e70439bd3daf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14836 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b94eb609ed4dd4a0a7d54bfe5f426e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3709 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train set size: 14836 samples\n",
      "  Test set size: 3709 samples\n",
      "Preparing dataset for identity term: lgbtq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5f763d06104b2fac66fb9ba2c183ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16756 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad32e83e04c49d8b96a9e86950bc5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4189 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train set size: 16756 samples\n",
      "  Test set size: 4189 samples\n",
      "Preparing dataset for identity term: mental_dis\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8049f4daebad4a4ead77d4ed06910008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14927 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe5e57c609845379d55c53ea9215989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train set size: 14927 samples\n",
      "  Test set size: 3732 samples\n",
      "Preparing dataset for identity term: mexican\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fca45dafb84abeb95e1f92863616b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16283 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10303c6e75834b969283a11d9e9027de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4070 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train set size: 16283 samples\n",
      "  Test set size: 4070 samples\n",
      "Preparing dataset for identity term: middle_east\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2f9f707b8d4cbd8f869be8eaf62104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16237 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb09f70f1224b0bb9b698e59dee9d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4060 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train set size: 16237 samples\n",
      "  Test set size: 4060 samples\n",
      "Preparing dataset for identity term: muslim\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6be948df9404ebbb37417d1559df2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15884 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb920faae8d4164909892cf33b71254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3971 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train set size: 15884 samples\n",
      "  Test set size: 3971 samples\n",
      "Preparing dataset for identity term: native_american\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1088734bff24ecfa749274b615cba23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62628942b62a461f8351f5c34bb6664c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train set size: 15488 samples\n",
      "  Test set size: 3872 samples\n",
      "Preparing dataset for identity term: physical_dis\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f993b8b8f3084e90b91963b445953c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12399 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d1eecc57e64ff8a327eadef30bc338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train set size: 12399 samples\n",
      "  Test set size: 3100 samples\n",
      "Preparing dataset for identity term: women\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2122d3e79f4730814e8ea3cff1198b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15260 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b404383f0d3479e8556a1fbeaa0eaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3815 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train set size: 15260 samples\n",
      "  Test set size: 3815 samples\n"
     ]
    }
   ],
   "source": [
    "# Prepare datasets for each identity term\n",
    "term_datasets = {}\n",
    "for term in id_terms:\n",
    "    term_datasets[term] = prepare_id_term_dataset(term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1940d089",
   "metadata": {},
   "source": [
    "## 3. Define Model Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244aaf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric helper method\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    probs = torch.nn.functional.softmax(torch.tensor(eval_pred.predictions), dim=-1)\n",
    "\n",
    "    try:\n",
    "        f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "        aucroc = roc_auc_score(labels, probs[:, 1].numpy())\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating metrics: {e}\")\n",
    "        f1 = 0.0\n",
    "        aucroc = 0.5\n",
    "    \n",
    "    return {\n",
    "        \"f1\": f1,\n",
    "        \"aucroc\": aucroc\n",
    "    }\n",
    "\n",
    "# Prepare model labels\n",
    "labels = [\"no hate\", \"hate\"]\n",
    "num_labels = len(labels)\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "# Function to create a model\n",
    "def create_model():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_id, num_labels=num_labels, label2id=label2id, id2label=id2label\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Function to train a model for a specific identity term\n",
    "def train_model_for_term(term, tokenized_dataset, epochs=3):\n",
    "    print(f\"\\nTraining model for identity term: {term}...\")\n",
    "    \n",
    "    model = create_model()\n",
    "    model.to(device)\n",
    "    \n",
    "    output_dir = f\"{ensemble_models_dir}/{term}-model\"\n",
    "    \n",
    "    # Define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=32,\n",
    "        learning_rate=2e-5,\n",
    "        num_train_epochs=epochs,\n",
    "        warmup_ratio=0.1,\n",
    "        weight_decay=0.01,\n",
    "        bf16=torch.cuda.is_available(),\n",
    "        fp16=not torch.cuda.is_available() and hasattr(torch, 'has_mps'),\n",
    "        optim=\"adamw_torch_fused\" if torch.cuda.is_available() else \"adamw_torch\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=50,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=100,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=100,\n",
    "        save_total_limit=2,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True,\n",
    "        gradient_accumulation_steps=2,\n",
    "        report_to=\"tensorboard\",\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping_callback = EarlyStoppingCallback(\n",
    "        early_stopping_patience=3,\n",
    "        early_stopping_threshold=0.001\n",
    "    )\n",
    "    \n",
    "    # Create a Trainer instance\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"test\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[early_stopping_callback]\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save the model and tokenizer\n",
    "    model_path = f\"{ensemble_models_dir}/{term}-final\"\n",
    "    tokenizer_path = f\"{ensemble_models_dir}/{term}-tokenizer\"\n",
    "    model.save_pretrained(model_path)\n",
    "    tokenizer.save_pretrained(tokenizer_path)\n",
    "    \n",
    "    print(f\"Model for {term} saved to {model_path}\")\n",
    "    \n",
    "    return {\n",
    "        \"model_path\": model_path,\n",
    "        \"tokenizer_path\": tokenizer_path\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2b2f0d",
   "metadata": {},
   "source": [
    "## 4. Train Individual Models for Each Identity Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc0566f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for identity term: asian...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1400' max='1491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1400/1491 05:26 < 00:21, 4.28 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.748500</td>\n",
       "      <td>0.360530</td>\n",
       "      <td>0.829420</td>\n",
       "      <td>0.903263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.544700</td>\n",
       "      <td>0.283449</td>\n",
       "      <td>0.873079</td>\n",
       "      <td>0.939844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.522200</td>\n",
       "      <td>0.258208</td>\n",
       "      <td>0.886346</td>\n",
       "      <td>0.948953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.456100</td>\n",
       "      <td>0.246797</td>\n",
       "      <td>0.899618</td>\n",
       "      <td>0.956256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.461700</td>\n",
       "      <td>0.260436</td>\n",
       "      <td>0.882647</td>\n",
       "      <td>0.959715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.289900</td>\n",
       "      <td>0.243214</td>\n",
       "      <td>0.905300</td>\n",
       "      <td>0.963654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.316600</td>\n",
       "      <td>0.221916</td>\n",
       "      <td>0.906664</td>\n",
       "      <td>0.965240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.346600</td>\n",
       "      <td>0.239119</td>\n",
       "      <td>0.907871</td>\n",
       "      <td>0.967012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.313900</td>\n",
       "      <td>0.216654</td>\n",
       "      <td>0.916760</td>\n",
       "      <td>0.968908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.227710</td>\n",
       "      <td>0.914855</td>\n",
       "      <td>0.968106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.333669</td>\n",
       "      <td>0.921290</td>\n",
       "      <td>0.968471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>0.366766</td>\n",
       "      <td>0.915343</td>\n",
       "      <td>0.968592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.371862</td>\n",
       "      <td>0.916362</td>\n",
       "      <td>0.968217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.371595</td>\n",
       "      <td>0.915960</td>\n",
       "      <td>0.968266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for asian saved to modernbert_ensemble/asian-final\n",
      "\n",
      "Training model for identity term: black...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='900' max='1491' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 900/1491 03:31 < 02:18, 4.25 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.784600</td>\n",
       "      <td>0.392759</td>\n",
       "      <td>0.832020</td>\n",
       "      <td>0.907766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.581800</td>\n",
       "      <td>0.305620</td>\n",
       "      <td>0.870873</td>\n",
       "      <td>0.938561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.565200</td>\n",
       "      <td>0.262362</td>\n",
       "      <td>0.885369</td>\n",
       "      <td>0.950068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.498200</td>\n",
       "      <td>0.254413</td>\n",
       "      <td>0.881188</td>\n",
       "      <td>0.956481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.425100</td>\n",
       "      <td>0.236011</td>\n",
       "      <td>0.898421</td>\n",
       "      <td>0.959694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.288200</td>\n",
       "      <td>0.242714</td>\n",
       "      <td>0.911921</td>\n",
       "      <td>0.964246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.329400</td>\n",
       "      <td>0.284407</td>\n",
       "      <td>0.898137</td>\n",
       "      <td>0.963483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.270655</td>\n",
       "      <td>0.904496</td>\n",
       "      <td>0.964222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.238162</td>\n",
       "      <td>0.906887</td>\n",
       "      <td>0.965577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for black saved to modernbert_ensemble/black-final\n",
      "\n",
      "Training model for identity term: chinese...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1428' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1428 03:50 < 01:38, 4.34 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.796100</td>\n",
       "      <td>0.353649</td>\n",
       "      <td>0.826581</td>\n",
       "      <td>0.897232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.640700</td>\n",
       "      <td>0.272257</td>\n",
       "      <td>0.878534</td>\n",
       "      <td>0.936988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.578800</td>\n",
       "      <td>0.273773</td>\n",
       "      <td>0.881426</td>\n",
       "      <td>0.941978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.489700</td>\n",
       "      <td>0.255119</td>\n",
       "      <td>0.888707</td>\n",
       "      <td>0.953426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>0.248222</td>\n",
       "      <td>0.902269</td>\n",
       "      <td>0.956497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.283200</td>\n",
       "      <td>0.300485</td>\n",
       "      <td>0.901374</td>\n",
       "      <td>0.956845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.288100</td>\n",
       "      <td>0.254805</td>\n",
       "      <td>0.906638</td>\n",
       "      <td>0.957403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.261200</td>\n",
       "      <td>0.258502</td>\n",
       "      <td>0.901418</td>\n",
       "      <td>0.957740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.261500</td>\n",
       "      <td>0.254184</td>\n",
       "      <td>0.902539</td>\n",
       "      <td>0.961100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.310694</td>\n",
       "      <td>0.900519</td>\n",
       "      <td>0.960356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for chinese saved to modernbert_ensemble/chinese-final\n",
      "\n",
      "Training model for identity term: jewish...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1300' max='1467' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1300/1467 04:57 < 00:38, 4.36 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.782200</td>\n",
       "      <td>0.376113</td>\n",
       "      <td>0.828628</td>\n",
       "      <td>0.907312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.601800</td>\n",
       "      <td>0.310864</td>\n",
       "      <td>0.857786</td>\n",
       "      <td>0.930356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.577900</td>\n",
       "      <td>0.268348</td>\n",
       "      <td>0.881691</td>\n",
       "      <td>0.948171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.568900</td>\n",
       "      <td>0.279997</td>\n",
       "      <td>0.873532</td>\n",
       "      <td>0.953619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.462700</td>\n",
       "      <td>0.239325</td>\n",
       "      <td>0.900823</td>\n",
       "      <td>0.960779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.306200</td>\n",
       "      <td>0.269239</td>\n",
       "      <td>0.905391</td>\n",
       "      <td>0.962739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.323600</td>\n",
       "      <td>0.251495</td>\n",
       "      <td>0.909612</td>\n",
       "      <td>0.962942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>0.245753</td>\n",
       "      <td>0.907775</td>\n",
       "      <td>0.964442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.299100</td>\n",
       "      <td>0.235418</td>\n",
       "      <td>0.907975</td>\n",
       "      <td>0.965669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.223900</td>\n",
       "      <td>0.252167</td>\n",
       "      <td>0.912773</td>\n",
       "      <td>0.966637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>0.372086</td>\n",
       "      <td>0.911345</td>\n",
       "      <td>0.966784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.380515</td>\n",
       "      <td>0.909298</td>\n",
       "      <td>0.966456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.392353</td>\n",
       "      <td>0.911258</td>\n",
       "      <td>0.966964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for jewish saved to modernbert_ensemble/jewish-final\n",
      "\n",
      "Training model for identity term: latino...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1392' max='1392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1392/1392 05:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.955700</td>\n",
       "      <td>0.453394</td>\n",
       "      <td>0.783988</td>\n",
       "      <td>0.842885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.787400</td>\n",
       "      <td>0.378718</td>\n",
       "      <td>0.824537</td>\n",
       "      <td>0.891834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.664900</td>\n",
       "      <td>0.317540</td>\n",
       "      <td>0.856186</td>\n",
       "      <td>0.929023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.613300</td>\n",
       "      <td>0.297809</td>\n",
       "      <td>0.866673</td>\n",
       "      <td>0.938939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.501900</td>\n",
       "      <td>0.309710</td>\n",
       "      <td>0.869989</td>\n",
       "      <td>0.942941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>0.316682</td>\n",
       "      <td>0.868720</td>\n",
       "      <td>0.945628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.405800</td>\n",
       "      <td>0.294124</td>\n",
       "      <td>0.874513</td>\n",
       "      <td>0.945927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.294875</td>\n",
       "      <td>0.880993</td>\n",
       "      <td>0.950541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.365300</td>\n",
       "      <td>0.304158</td>\n",
       "      <td>0.883540</td>\n",
       "      <td>0.948855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.153700</td>\n",
       "      <td>0.333674</td>\n",
       "      <td>0.886963</td>\n",
       "      <td>0.951296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>0.438930</td>\n",
       "      <td>0.884066</td>\n",
       "      <td>0.948769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.442494</td>\n",
       "      <td>0.888904</td>\n",
       "      <td>0.950202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.129200</td>\n",
       "      <td>0.455359</td>\n",
       "      <td>0.886884</td>\n",
       "      <td>0.949437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for latino saved to modernbert_ensemble/latino-final\n",
      "\n",
      "Training model for identity term: lgbtq...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1572' max='1572' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1572/1572 06:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.833400</td>\n",
       "      <td>0.354124</td>\n",
       "      <td>0.829564</td>\n",
       "      <td>0.875153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.638300</td>\n",
       "      <td>0.282652</td>\n",
       "      <td>0.867586</td>\n",
       "      <td>0.923743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.570700</td>\n",
       "      <td>0.240785</td>\n",
       "      <td>0.894002</td>\n",
       "      <td>0.945462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.503700</td>\n",
       "      <td>0.225661</td>\n",
       "      <td>0.891454</td>\n",
       "      <td>0.954173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.448200</td>\n",
       "      <td>0.198382</td>\n",
       "      <td>0.910695</td>\n",
       "      <td>0.963319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.323200</td>\n",
       "      <td>0.214983</td>\n",
       "      <td>0.908560</td>\n",
       "      <td>0.962696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.310800</td>\n",
       "      <td>0.205544</td>\n",
       "      <td>0.917840</td>\n",
       "      <td>0.963757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.319300</td>\n",
       "      <td>0.200902</td>\n",
       "      <td>0.916844</td>\n",
       "      <td>0.964843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.290100</td>\n",
       "      <td>0.198634</td>\n",
       "      <td>0.918881</td>\n",
       "      <td>0.966767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.269400</td>\n",
       "      <td>0.202878</td>\n",
       "      <td>0.919308</td>\n",
       "      <td>0.968384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.105800</td>\n",
       "      <td>0.259926</td>\n",
       "      <td>0.917560</td>\n",
       "      <td>0.967243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.295365</td>\n",
       "      <td>0.920713</td>\n",
       "      <td>0.967398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.326952</td>\n",
       "      <td>0.919559</td>\n",
       "      <td>0.966644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.126700</td>\n",
       "      <td>0.331011</td>\n",
       "      <td>0.922177</td>\n",
       "      <td>0.966753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.333358</td>\n",
       "      <td>0.922555</td>\n",
       "      <td>0.966902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for lgbtq saved to modernbert_ensemble/lgbtq-final\n",
      "\n",
      "Training model for identity term: mental_dis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1398' max='1398' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1398/1398 05:16, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.774000</td>\n",
       "      <td>0.339313</td>\n",
       "      <td>0.824712</td>\n",
       "      <td>0.897034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>0.274191</td>\n",
       "      <td>0.881040</td>\n",
       "      <td>0.948359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.438100</td>\n",
       "      <td>0.210305</td>\n",
       "      <td>0.911020</td>\n",
       "      <td>0.959729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.373300</td>\n",
       "      <td>0.183355</td>\n",
       "      <td>0.921489</td>\n",
       "      <td>0.968740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.300300</td>\n",
       "      <td>0.192486</td>\n",
       "      <td>0.926170</td>\n",
       "      <td>0.969464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.253100</td>\n",
       "      <td>0.176522</td>\n",
       "      <td>0.928409</td>\n",
       "      <td>0.972778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.313300</td>\n",
       "      <td>0.219939</td>\n",
       "      <td>0.921897</td>\n",
       "      <td>0.975019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.261300</td>\n",
       "      <td>0.173381</td>\n",
       "      <td>0.933857</td>\n",
       "      <td>0.975842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>0.165461</td>\n",
       "      <td>0.933690</td>\n",
       "      <td>0.977743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.210529</td>\n",
       "      <td>0.935265</td>\n",
       "      <td>0.978019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.064400</td>\n",
       "      <td>0.239309</td>\n",
       "      <td>0.936768</td>\n",
       "      <td>0.978362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.253702</td>\n",
       "      <td>0.935787</td>\n",
       "      <td>0.977829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.076700</td>\n",
       "      <td>0.260568</td>\n",
       "      <td>0.936673</td>\n",
       "      <td>0.977684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for mental_dis saved to modernbert_ensemble/mental_dis-final\n",
      "\n",
      "Training model for identity term: mexican...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1200' max='1527' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1200/1527 04:36 < 01:15, 4.33 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.829500</td>\n",
       "      <td>0.344116</td>\n",
       "      <td>0.841378</td>\n",
       "      <td>0.907766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.573400</td>\n",
       "      <td>0.258384</td>\n",
       "      <td>0.885654</td>\n",
       "      <td>0.950419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.539100</td>\n",
       "      <td>0.221546</td>\n",
       "      <td>0.903516</td>\n",
       "      <td>0.963544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.484600</td>\n",
       "      <td>0.212362</td>\n",
       "      <td>0.909198</td>\n",
       "      <td>0.967116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.464700</td>\n",
       "      <td>0.198205</td>\n",
       "      <td>0.910791</td>\n",
       "      <td>0.970956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.316800</td>\n",
       "      <td>0.234145</td>\n",
       "      <td>0.903731</td>\n",
       "      <td>0.970317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.341600</td>\n",
       "      <td>0.198201</td>\n",
       "      <td>0.914198</td>\n",
       "      <td>0.971757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.207903</td>\n",
       "      <td>0.914246</td>\n",
       "      <td>0.973513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.268300</td>\n",
       "      <td>0.198826</td>\n",
       "      <td>0.923117</td>\n",
       "      <td>0.974905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.251700</td>\n",
       "      <td>0.207200</td>\n",
       "      <td>0.921637</td>\n",
       "      <td>0.975142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.312505</td>\n",
       "      <td>0.920930</td>\n",
       "      <td>0.974532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.352866</td>\n",
       "      <td>0.920383</td>\n",
       "      <td>0.974754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for mexican saved to modernbert_ensemble/mexican-final\n",
      "\n",
      "Training model for identity term: middle_east...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='1521' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 700/1521 02:41 < 03:10, 4.32 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.852400</td>\n",
       "      <td>0.351669</td>\n",
       "      <td>0.843587</td>\n",
       "      <td>0.907243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.309169</td>\n",
       "      <td>0.871942</td>\n",
       "      <td>0.946140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.499600</td>\n",
       "      <td>0.223414</td>\n",
       "      <td>0.902988</td>\n",
       "      <td>0.964020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.211320</td>\n",
       "      <td>0.911462</td>\n",
       "      <td>0.967734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>0.222270</td>\n",
       "      <td>0.909022</td>\n",
       "      <td>0.968763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.238800</td>\n",
       "      <td>0.301918</td>\n",
       "      <td>0.910806</td>\n",
       "      <td>0.972405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.281456</td>\n",
       "      <td>0.899034</td>\n",
       "      <td>0.969521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for middle_east saved to modernbert_ensemble/middle_east-final\n",
      "\n",
      "Training model for identity term: muslim...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1300' max='1488' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1300/1488 04:58 < 00:43, 4.34 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.844700</td>\n",
       "      <td>0.374081</td>\n",
       "      <td>0.829848</td>\n",
       "      <td>0.881170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.652400</td>\n",
       "      <td>0.343830</td>\n",
       "      <td>0.823962</td>\n",
       "      <td>0.924915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.614900</td>\n",
       "      <td>0.294128</td>\n",
       "      <td>0.863878</td>\n",
       "      <td>0.939667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>0.256620</td>\n",
       "      <td>0.889929</td>\n",
       "      <td>0.951434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.466700</td>\n",
       "      <td>0.257104</td>\n",
       "      <td>0.894156</td>\n",
       "      <td>0.956152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.246879</td>\n",
       "      <td>0.897983</td>\n",
       "      <td>0.958667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.330100</td>\n",
       "      <td>0.246788</td>\n",
       "      <td>0.906037</td>\n",
       "      <td>0.958303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.246478</td>\n",
       "      <td>0.907700</td>\n",
       "      <td>0.960910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.323700</td>\n",
       "      <td>0.229772</td>\n",
       "      <td>0.909917</td>\n",
       "      <td>0.962998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.298700</td>\n",
       "      <td>0.221302</td>\n",
       "      <td>0.913310</td>\n",
       "      <td>0.963829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.333011</td>\n",
       "      <td>0.905245</td>\n",
       "      <td>0.961929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.375729</td>\n",
       "      <td>0.908865</td>\n",
       "      <td>0.961429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.110400</td>\n",
       "      <td>0.379268</td>\n",
       "      <td>0.909111</td>\n",
       "      <td>0.961937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for muslim saved to modernbert_ensemble/muslim-final\n",
      "\n",
      "Training model for identity term: native_american...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='900' max='1452' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 900/1452 03:25 < 02:06, 4.37 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.340663</td>\n",
       "      <td>0.837903</td>\n",
       "      <td>0.899874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.591200</td>\n",
       "      <td>0.283450</td>\n",
       "      <td>0.871720</td>\n",
       "      <td>0.927527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.479300</td>\n",
       "      <td>0.264171</td>\n",
       "      <td>0.885599</td>\n",
       "      <td>0.941960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.450400</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.900126</td>\n",
       "      <td>0.957327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>0.225138</td>\n",
       "      <td>0.906350</td>\n",
       "      <td>0.959433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.284800</td>\n",
       "      <td>0.228598</td>\n",
       "      <td>0.913555</td>\n",
       "      <td>0.963511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.273700</td>\n",
       "      <td>0.225951</td>\n",
       "      <td>0.911514</td>\n",
       "      <td>0.965068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.263600</td>\n",
       "      <td>0.225841</td>\n",
       "      <td>0.907234</td>\n",
       "      <td>0.962385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.249500</td>\n",
       "      <td>0.232936</td>\n",
       "      <td>0.912682</td>\n",
       "      <td>0.962510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for native_american saved to modernbert_ensemble/native_american-final\n",
      "\n",
      "Training model for identity term: physical_dis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='900' max='1161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 900/1161 03:15 < 00:56, 4.58 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.782800</td>\n",
       "      <td>0.361877</td>\n",
       "      <td>0.834972</td>\n",
       "      <td>0.886636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.583500</td>\n",
       "      <td>0.297338</td>\n",
       "      <td>0.861503</td>\n",
       "      <td>0.924388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.522100</td>\n",
       "      <td>0.261884</td>\n",
       "      <td>0.874064</td>\n",
       "      <td>0.945516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.467100</td>\n",
       "      <td>0.250853</td>\n",
       "      <td>0.889715</td>\n",
       "      <td>0.944341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>0.256659</td>\n",
       "      <td>0.898656</td>\n",
       "      <td>0.949949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>0.234941</td>\n",
       "      <td>0.909018</td>\n",
       "      <td>0.955877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.323600</td>\n",
       "      <td>0.236033</td>\n",
       "      <td>0.900559</td>\n",
       "      <td>0.955280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.205100</td>\n",
       "      <td>0.286936</td>\n",
       "      <td>0.902273</td>\n",
       "      <td>0.955214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.126800</td>\n",
       "      <td>0.352116</td>\n",
       "      <td>0.904044</td>\n",
       "      <td>0.957650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for physical_dis saved to modernbert_ensemble/physical_dis-final\n",
      "\n",
      "Training model for identity term: women...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='900' max='1431' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 900/1431 03:25 < 02:01, 4.37 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Aucroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.742500</td>\n",
       "      <td>0.333383</td>\n",
       "      <td>0.826191</td>\n",
       "      <td>0.894307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.604100</td>\n",
       "      <td>0.281480</td>\n",
       "      <td>0.870887</td>\n",
       "      <td>0.922107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.490300</td>\n",
       "      <td>0.242690</td>\n",
       "      <td>0.888025</td>\n",
       "      <td>0.943718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.518800</td>\n",
       "      <td>0.219708</td>\n",
       "      <td>0.902295</td>\n",
       "      <td>0.954889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.430100</td>\n",
       "      <td>0.252338</td>\n",
       "      <td>0.889137</td>\n",
       "      <td>0.953958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.268100</td>\n",
       "      <td>0.241357</td>\n",
       "      <td>0.909513</td>\n",
       "      <td>0.958211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.217408</td>\n",
       "      <td>0.908229</td>\n",
       "      <td>0.958620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.236327</td>\n",
       "      <td>0.906326</td>\n",
       "      <td>0.956318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.322000</td>\n",
       "      <td>0.230242</td>\n",
       "      <td>0.908193</td>\n",
       "      <td>0.958171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for women saved to modernbert_ensemble/women-final\n"
     ]
    }
   ],
   "source": [
    "# Train models for each identity term\n",
    "trained_models = {}\n",
    "\n",
    "for term in id_terms:\n",
    "    trained_models[term] = train_model_for_term(term, term_datasets[term])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f44d6f",
   "metadata": {},
   "source": [
    "## 5. Ensemble Methods Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d1e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleClassifier:\n",
    "    def __init__(self, model_paths, voting=\"majority\", weights=None):\n",
    "        \"\"\"\n",
    "        Initialize the ensemble classifier.\n",
    "        \n",
    "        Parameters:\n",
    "        - model_paths: Dictionary mapping term names to dictionaries with 'model_path' and 'tokenizer_path'\n",
    "        - voting: String, voting mechanism to use ('majority', 'weighted_average')\n",
    "        - weights: Optional dictionary mapping term names to weights for weighted averaging\n",
    "        \"\"\"\n",
    "        self.model_paths = model_paths\n",
    "        self.voting = voting\n",
    "        self.models = {}\n",
    "        self.tokenizers = {}\n",
    "        self.pipelines = {}\n",
    "        self.term_names = list(model_paths.keys())\n",
    "        \n",
    "        # Default to equal weights if none provided\n",
    "        if weights is None:\n",
    "            self.weights = {term: 1.0/len(model_paths) for term in model_paths.keys()}\n",
    "        else:\n",
    "            self.weights = weights\n",
    "            # Normalize weights to sum to 1\n",
    "            weight_sum = sum(self.weights.values())\n",
    "            self.weights = {k: v/weight_sum for k, v in self.weights.items()}\n",
    "        \n",
    "        # Load models and tokenizers\n",
    "        for term, paths in model_paths.items():\n",
    "            print(f\"Loading model for {term}...\")\n",
    "            self.tokenizers[term] = AutoTokenizer.from_pretrained(paths['tokenizer_path'])\n",
    "            self.models[term] = AutoModelForSequenceClassification.from_pretrained(paths['model_path'])\n",
    "            self.models[term].to(device)\n",
    "            \n",
    "            # Create pipeline\n",
    "            self.pipelines[term] = pipeline(\n",
    "                task=\"text-classification\",\n",
    "                tokenizer=self.tokenizers[term],\n",
    "                model=self.models[term],\n",
    "                device=0 if torch.cuda.is_available() else -1\n",
    "            )\n",
    "    \n",
    "    def predict(self, texts):\n",
    "        \"\"\"\n",
    "        Make predictions using the ensemble.\n",
    "        \n",
    "        Parameters:\n",
    "        - texts: List of strings, texts to classify\n",
    "        \n",
    "        Returns:\n",
    "        - predictions: List of prediction labels\n",
    "        - confidences: List of confidence scores\n",
    "        \"\"\"\n",
    "        if not isinstance(texts, list):\n",
    "            texts = [texts]\n",
    "        \n",
    "        # Determine batch size based on available memory\n",
    "        batch_size = 32\n",
    "        \n",
    "        # Process in batches for better performance\n",
    "        all_model_scores = {term: [] for term in self.term_names}\n",
    "        \n",
    "        # Process each term's model in batches\n",
    "        for term in self.term_names:\n",
    "            model = self.models[term]\n",
    "            tokenizer = self.tokenizers[term]\n",
    "            \n",
    "            model_scores = []\n",
    "            \n",
    "            # Process texts in batches\n",
    "            for i in range(0, len(texts), batch_size):\n",
    "                batch_texts = texts[i:i+batch_size]\n",
    "                \n",
    "                # Tokenize\n",
    "                inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=140)\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                \n",
    "                # Get predictions\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    logits = outputs.logits\n",
    "                    probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "                    \n",
    "                    # Get probability of hate class (index 1)\n",
    "                    hate_probs = probs[:, 1].cpu().numpy()\n",
    "                    model_scores.extend(hate_probs)\n",
    "            \n",
    "            all_model_scores[term] = np.array(model_scores)\n",
    "        \n",
    "        # Apply ensemble method\n",
    "        final_predictions = []\n",
    "        final_confidences = []\n",
    "        \n",
    "        # Convert to numpy arrays for vectorized operations\n",
    "        model_scores_array = np.array([all_model_scores[term] for term in self.term_names])\n",
    "        \n",
    "        if self.voting == \"majority\":\n",
    "            # Convert scores to binary predictions (1 for hate, 0 for no hate)\n",
    "            binary_preds = (model_scores_array >= 0.5).astype(int)\n",
    "            \n",
    "            # Sum across models (axis 0) to get votes for each text\n",
    "            vote_counts = np.sum(binary_preds, axis=0)\n",
    "            \n",
    "            # Majority rule\n",
    "            hate_predictions = vote_counts > (len(self.term_names) / 2)\n",
    "            \n",
    "            # Calculate confidence as proportion of votes\n",
    "            confidences = np.maximum(vote_counts, len(self.term_names) - vote_counts) / len(self.term_names)\n",
    "            \n",
    "            # Convert to strings and list\n",
    "            final_predictions = [\"hate\" if pred else \"no hate\" for pred in hate_predictions]\n",
    "            final_confidences = confidences.tolist()\n",
    "            \n",
    "        elif self.voting == \"weighted_average\":\n",
    "            # Apply weights to each model's predictions\n",
    "            weights_array = np.array([self.weights[term] for term in self.term_names])\n",
    "            \n",
    "            # Weighted sum of scores (weights_array[:, np.newaxis] broadcasts weights across all samples)\n",
    "            weighted_scores = np.sum(model_scores_array * weights_array[:, np.newaxis], axis=0)\n",
    "            \n",
    "            # Classify based on threshold\n",
    "            hate_predictions = weighted_scores >= 0.5\n",
    "            \n",
    "            # Confidence is max of score or 1-score\n",
    "            confidences = np.maximum(weighted_scores, 1 - weighted_scores)\n",
    "            \n",
    "            # Convert to strings and list\n",
    "            final_predictions = [\"hate\" if pred else \"no hate\" for pred in hate_predictions]\n",
    "            final_confidences = confidences.tolist()\n",
    "        \n",
    "        return final_predictions, final_confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf53992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CheckList wrapper for the ensemble classifier\n",
    "class EnsembleClassifierWrapper(PredictorWrapper):\n",
    "    def __init__(self, ensemble_classifier):\n",
    "        self.ensemble = ensemble_classifier\n",
    "        \n",
    "    def __call__(self, texts):\n",
    "        predictions, confidences = self.ensemble.predict(texts)\n",
    "        return predictions, confidences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2b1c82",
   "metadata": {},
   "source": [
    "## 6. Load or Create the Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc3c2dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing model for asian\n",
      "Found existing model for black\n",
      "Found existing model for chinese\n",
      "Found existing model for jewish\n",
      "Found existing model for latino\n",
      "Found existing model for lgbtq\n",
      "Found existing model for mental_dis\n",
      "Found existing model for mexican\n",
      "Found existing model for middle_east\n",
      "Found existing model for muslim\n",
      "Found existing model for native_american\n",
      "Found existing model for physical_dis\n",
      "Found existing model for women\n",
      "Loaded 13 existing models\n",
      "Using pre-trained models for all identity terms\n"
     ]
    }
   ],
   "source": [
    "# Check if models are already trained and available\n",
    "def load_trained_models():\n",
    "    trained_models = {}\n",
    "    for term in id_terms:\n",
    "        model_path = f\"{ensemble_models_dir}/{term}-final\"\n",
    "        tokenizer_path = f\"{ensemble_models_dir}/{term}-tokenizer\"\n",
    "        \n",
    "        if os.path.exists(model_path) and os.path.exists(tokenizer_path):\n",
    "            trained_models[term] = {\n",
    "                \"model_path\": model_path,\n",
    "                \"tokenizer_path\": tokenizer_path\n",
    "            }\n",
    "            print(f\"Found existing model for {term}\")\n",
    "    \n",
    "    return trained_models\n",
    "\n",
    "# Try to load existing models first\n",
    "loaded_models = load_trained_models()\n",
    "print(f\"Loaded {len(loaded_models)} existing models\")\n",
    "\n",
    "# If we have models for all terms, use them\n",
    "if len(loaded_models) == len(id_terms):\n",
    "    trained_models = loaded_models\n",
    "    print(\"Using pre-trained models for all identity terms\")\n",
    "else:\n",
    "    # Train models that are missing\n",
    "    missing_terms = set(id_terms) - set(loaded_models.keys())\n",
    "    for term in missing_terms:\n",
    "        print(f\"Training model for {term} as it was not found\")\n",
    "        term_model_info = train_model_for_term(term, term_datasets[term])\n",
    "        loaded_models[term] = term_model_info\n",
    "    \n",
    "    trained_models = loaded_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa8e1fb",
   "metadata": {},
   "source": [
    "## 7. Evaluate Models on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1836bc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test data with 996 samples\n"
     ]
    }
   ],
   "source": [
    "# Get annotated Russian test dataset\n",
    "test_dict = dh.getAnnotadedRussTest()\n",
    "print(f\"Loaded test data with {len(test_dict['text'])} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d76d2bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for asian...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for black...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for chinese...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for jewish...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for latino...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for lgbtq...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for mental_dis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for mexican...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for middle_east...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for muslim...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for native_american...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for physical_dis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model for women...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting 996 examples\n",
      "Test cases:      996\n",
      "Fails (rate):    292 (29.3%)\n",
      "\n",
      "Example fails:\n",
      "hate                                                  not to the stupid city boy, to him there is no evidence.\n",
      "----\n",
      "hate russia wants revenge  sydney  rt russia &amp; former soviet union  correcting the historical wrong and making the criminals pay is called justice, not revenge. but the twat doesn't know better.\n",
      "----\n",
      "hate  i think starting world war over ukraine is stupid\n",
      "----\n",
      "Test cases:      996\n",
      "Fails (rate):    292 (29.3%)\n",
      "\n",
      "Example fails:\n",
      "hate                                                  not to the stupid city boy, to him there is no evidence.\n",
      "----\n",
      "hate russia wants revenge  sydney  rt russia &amp; former soviet union  correcting the historical wrong and making the criminals pay is called justice, not revenge. but the twat doesn't know better.\n",
      "----\n",
      "hate  i think starting world war over ukraine is stupid\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# Create and evaluate majority voting ensemble\n",
    "majority_ensemble = EnsembleClassifier(trained_models, voting=\"majority\")\n",
    "majority_wrapper = EnsembleClassifierWrapper(majority_ensemble)\n",
    "\n",
    "hate_test_majority = MFT(data=test_dict['text'], labels=test_dict['label'], name=\"Ensemble Majority Voting Test\")\n",
    "majority_results = hate_test_majority.run(majority_wrapper, overwrite=True)\n",
    "hate_test_majority.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0e594",
   "metadata": {},
   "source": [
    "## 10. Save the Best Ensemble Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5712feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimized weights\n",
    "import json\n",
    "\n",
    "# Save weights and model paths for later use\n",
    "ensemble_config = {\n",
    "    \"optimized_weights\": best_weights,\n",
    "    \"models\": {term: {\n",
    "        \"model_path\": info[\"model_path\"],\n",
    "        \"tokenizer_path\": info[\"tokenizer_path\"]\n",
    "    } for term, info in trained_models.items()}\n",
    "}\n",
    "\n",
    "with open(f\"{ensemble_models_dir}/ensemble_config.json\", \"w\") as f:\n",
    "    json.dump(ensemble_config, f, indent=2)\n",
    "\n",
    "print(f\"Ensemble configuration saved to {ensemble_models_dir}/ensemble_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f206a0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for using the saved ensemble in other notebooks\n",
    "def load_ensemble(config_path=None, voting=\"weighted_average\"):\n",
    "    \"\"\"\n",
    "    Load the ensemble from a saved configuration file.\n",
    "    \n",
    "    Parameters:\n",
    "    - config_path: Path to the ensemble configuration file. Defaults to ensemble_models_dir/ensemble_config.json\n",
    "    - voting: Which voting method to use ('majority', 'weighted_average')\n",
    "    \n",
    "    Returns:\n",
    "    - An initialized EnsembleClassifier\n",
    "    \"\"\"\n",
    "    if config_path is None:\n",
    "        config_path = f\"{ensemble_models_dir}/ensemble_config.json\"\n",
    "    \n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    return EnsembleClassifier(\n",
    "        config[\"models\"],\n",
    "        voting=voting,\n",
    "        weights=config[\"optimized_weights\"]\n",
    "    )\n",
    "\n",
    "# Example usage:\n",
    "# ensemble = load_ensemble()\n",
    "# predictions, confidences = ensemble.predict([\"This is a test sentence.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cce75d2",
   "metadata": {},
   "source": [
    "## 11. Plot Confusion Matrices for Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d2e2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot confusion matrices for the ensemble models\n",
    "def plot_confusion_matrix(ensemble, test_dict, ensemble_name):\n",
    "    wrapper = EnsembleClassifierWrapper(ensemble)\n",
    "    \n",
    "    predictions, confidences = wrapper(test_dict['text'])\n",
    "    \n",
    "    # Convert string predictions and true labels to binary\n",
    "    pred_binary = [1 if p == 'hate' else 0 for p in predictions]\n",
    "    true_binary = [1 if l == 'hate' else 0 for l in test_dict['label']]\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(true_binary, pred_binary)\n",
    "    \n",
    "    # Add percentages to confusion matrix\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "    group_percentages = [\"{0:.1%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2, 2)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', xticklabels=['No Hate', 'Hate'], yticklabels=['No Hate', 'Hate'])\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title(f'Confusion Matrix - {ensemble_name}')\n",
    "    plt.savefig(f\"{ensemble_models_dir}/{ensemble_name.replace(' ', '_').lower()}_confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate metrics from confusion matrix\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    balanced_acc = (recall + tn/(tn+fp))/2 if (tn+fp) > 0 else recall\n",
    "    \n",
    "    # Calculate AUC-ROC\n",
    "    try:\n",
    "        aucroc = roc_auc_score(true_binary, confidences)\n",
    "    except:\n",
    "        aucroc = 0.5\n",
    "    \n",
    "    print(f\"Metrics for {ensemble_name}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "    print(f\"  AUC-ROC: {aucroc:.4f}\")\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fa18f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Majority Voting Ensemble:\n",
      "  Accuracy: 0.7068\n",
      "  Balanced Accuracy: 0.7578\n",
      "  Precision: 0.4009\n",
      "  Recall: 0.8447\n",
      "  F1 Score: 0.5437\n",
      "  AUC-ROC: 0.4530\n"
     ]
    }
   ],
   "source": [
    "# Plot confusion matrix for majority voting ensemble\n",
    "majority_cm = plot_confusion_matrix(majority_ensemble, test_dict, \"Majority Voting Ensemble\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
